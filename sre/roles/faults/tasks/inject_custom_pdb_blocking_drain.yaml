---
- name: Retrieve worker nodes on the cluster
  kubernetes.core.k8s_info:
    api_version: v1
    kind: Node
    kubeconfig: "{{ faults_cluster.kubeconfig }}"
    label_selectors:
      - node-role.kubernetes.io/node =
  register: faults_nodes

- name: Validate that worker nodes exists
  ansible.builtin.assert:
    that:
      - faults_nodes is defined
      - faults_nodes.resources | length > 0
    fail_msg: Unable to find worker nodes. Please run this fault on a cluster with worker nodes.
    success_msg: Found worker nodes.

- name: Retrieve workload
  kubernetes.core.k8s_info:
    kubeconfig: "{{ faults_cluster.kubeconfig }}"
    api_version: apps/v1
    kind: "{{ spec.workload.kind }}"
    name: "{{ spec.workload.name }}"
    namespace: "{{ spec.workload.namespace }}"
  register: faults_workload

- name: Validate that workload exists
  ansible.builtin.assert:
    that:
      - faults_workload is defined
      - faults_workload.resources | length == 1
    fail_msg: Unable to find workload. Please verify that the workload exists.
    success_msg: Found workload.

- name: Assign workload to node
  kubernetes.core.k8s:
    kubeconfig: "{{ faults_cluster.kubeconfig }}"
    resource_definition:
      apiVersion: "{{ faults_workload.resources[0].apiVersion }}"
      kind: "{{ faults_workload.resources[0].kind }}"
      metadata:
        name: "{{ faults_workload.resources[0].metadata.name }}"
        namespace: "{{ faults_workload.resources[0].metadata.namespace }}"
      spec:
        template:
          spec:
            nodeSelector:
              "kubernetes.io/hostname": "{{ faults_nodes.resources[0].metadata.name }}"

- name: Wait for workload to update
  kubernetes.core.k8s_info:
    api_version: "{{ faults_workload.resources[0].apiVersion }}"
    kubeconfig: "{{ faults_cluster.kubeconfig }}"
    kind: "{{ faults_workload.resources[0].kind }}"
    name: "{{ faults_workload.resources[0].metadata.name }}"
    namespace: "{{ faults_workload.resources[0].metadata.namespace }}"
  register: faults_updated_workload
  until:
    - faults_updated_workload.resources | length == 1
    - faults_updated_workload.resources[0].status.availableReplicas == faults_updated_workload.resources[0].status.replicas
  delay: 15
  retries: 20

- name: Create Pod Disruption Budget
  kubernetes.core.k8s:
    kubeconfig: "{{ faults_cluster.kubeconfig }}"
    template: templates/drain_blocking_pod_disruption_budget/poddisruptionbudget.j2
    state: present
  vars:
    fault_args: "{{ spec }}"
    workload: "{{ faults_workload.resources | first }}"

- name: Drain node
  kubernetes.core.k8s_drain:
    delete_options:
      delete_emptydir_data: true
      ignore_daemonsets: true
    kubeconfig: "{{ faults_cluster.kubeconfig }}"
    name: "{{ faults_nodes.resources[0].metadata.name }}"

# - name: Cordon the target node
#   kubernetes.core.k8s_json_patch:
#     api_version: v1
#     kind: Node
#     kubeconfig: "{{ faults_cluster.kubeconfig }}"
#     name: "{{ faults_target_node }}"
#     patch:
#       - op: replace
#         path: /spec/unschedulable
#         value: true

# - name: Attempt drain operation (will hang due to PDB)
#   ansible.builtin.command:
#     cmd: >
#       kubectl drain {{ faults_target_node }}
#       --kubeconfig={{ faults_cluster.kubeconfig }}
#       --ignore-daemonsets
#       --delete-emptydir-data
#       --timeout=60s
#       --force
#   register: faults_drain_result
#   failed_when: false
#   changed_when: faults_drain_result.rc == 0
